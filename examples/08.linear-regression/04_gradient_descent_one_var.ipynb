{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent for Linear Regression\n",
    "# yhat = wx + b \n",
    "# mse = (y-yhat)**2 / 2m \n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress = True,\n",
    "   formatter = {'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  8 11 14]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "print((a * 3) + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, *gradient descent* was described as:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "where, parameters $w$, $b$ are updated simultaneously.  \n",
    "The gradient is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} ( \\hat{y}^{(i)} - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (\\hat{y}^{(i)} - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gradient descent function\n",
    "def gradient_descend(X, y, w, b, learning_rate): \n",
    "    m = X.shape[0]\n",
    "    y_pred = np.dot(X, w) + b\n",
    "    #print (\"y_pred\", y_pred)\n",
    "\n",
    "    sumDw = 0\n",
    "    sumDb = 0\n",
    "    for i in range(m):\n",
    "        sumDw += (y_pred[i]-y[i])*X[i]\n",
    "        sumDb += (y_pred[i]-y[i])\n",
    "        \n",
    "    dw = (1/m) * sumDw \n",
    "    db = (1/m) * sumDb\n",
    "    #print (\"dw\", dw)\n",
    "    #print (\"db\", db)\n",
    "\n",
    "    # Make an update to the w parameter \n",
    "    w = w - (learning_rate * dw)\n",
    "    b = b - (learning_rate * db)\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, learning_rate = 0.001):\n",
    "    # Parameters\n",
    "    w = 0.0 \n",
    "    b = 0.0 \n",
    "    \n",
    "    # Iteratively make updates\n",
    "    for epoch in range(10000): \n",
    "        w, b = gradient_descend(X, y, w, b, learning_rate)\n",
    "        # Debugging - Calculate the mse and print it every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            y_pred = np.dot(X, w) + b\n",
    "            mse = np.mean((y_pred-y)**2)\n",
    "            print(f'{epoch} mse is {mse}, paramters w:{w}, b:{b}')\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    y_pred = np.dot(X, w) + b\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,) (11,)\n",
      "0 mse is 40.0004658347107, paramters w:0.9895454545454546, b:0.02990909090909091\n",
      "100 mse is 22.1984113057095, paramters w:1.1254126280632555, b:0.19418203812112242\n",
      "200 mse is 21.712903688074714, paramters w:1.1209612381068403, b:0.34992985507624\n",
      "300 mse is 21.254343940743905, paramters w:1.1166351477898266, b:0.5012936154797735\n",
      "400 mse is 20.821236334942622, paramters w:1.1124308301240635, b:0.6483967236414796\n",
      "500 mse is 20.41216816161338, paramters w:1.1083448574005785, b:0.7913591102335173\n",
      "600 mse is 20.025805123445725, paramters w:1.1043738983950269, b:0.9302973300678952\n",
      "700 mse is 19.66088698266922, paramters w:1.1005147156517991, b:1.0653246571216322\n",
      "800 mse is 19.316223450413812, paramters w:1.0967641628445792, b:1.196551176887114\n",
      "900 mse is 18.990690304229354, paramters w:1.0931191822111979, b:1.3240838761229292\n",
      "1000 mse is 18.68322572110012, paramters w:1.0895768020606906, b:1.4480267300783645\n",
      "1100 mse is 18.392826813993853, paramters w:1.0861341343505284, b:1.5684807872626576\n",
      "1200 mse is 18.11854636064789, paramters w:1.0827883723320462, b:1.6855442518281405\n",
      "1300 mse is 17.859489713922496, paramters w:1.0795367882621474, b:1.7993125636344223\n",
      "1400 mse is 17.61481188364359, paramters w:1.0763767311794215, b:1.9098784760588823\n",
      "1500 mse is 17.383714780416373, paramters w:1.0733056247428603, b:2.017332131616937\n",
      "1600 mse is 17.16544461241982, paramters w:1.0703209651314107, b:2.121761135453695\n",
      "1700 mse is 16.959289426690813, paramters w:1.0674203190026512, b:2.2232506267669643\n",
      "1800 mse is 16.76457678687814, paramters w:1.0646013215089307, b:2.3218833482197785\n",
      "1900 mse is 16.58067157989172, paramters w:1.0618616743693454, b:2.4177397133991043\n",
      "2000 mse is 16.40697394429262, paramters w:1.059199143995993, b:2.510897872375664\n",
      "2100 mse is 16.242917313666922, paramters w:1.0566115596729622, b:2.6014337754183727\n",
      "2200 mse is 16.08796656860105, paramters w:1.054096811786589, b:2.6894212349153057\n",
      "2300 mse is 15.941616291230991, paramters w:1.0516528501055211, b:2.7749319855516834\n",
      "2400 mse is 15.803389116671822, paramters w:1.0492776821092005, b:2.85803574279395\n",
      "2500 mse is 15.672834175950431, paramters w:1.0469693713633952, b:2.9388002597276084\n",
      "2600 mse is 15.549525625362396, paramters w:1.044726035941457, b:3.017291382295163\n",
      "2700 mse is 15.43306125745641, paramters w:1.0425458468900184, b:3.09357310297921\n",
      "2800 mse is 15.323061189115197, paramters w:1.040427026737878, b:3.1677076129744037\n",
      "2900 mse is 15.219166622453912, paramters w:1.0383678480468588, b:3.2397553528909113\n",
      "3000 mse is 15.121038674494327, paramters w:1.0363666320034561, b:3.3097750620305986\n",
      "3100 mse is 15.028357271797422, paramters w:1.0344217470501307, b:3.377823826276189\n",
      "3200 mse is 14.940820106448689, paramters w:1.0325316075551263, b:3.4439571246324316\n",
      "3300 mse is 14.858141649991252, paramters w:1.0306946725197315, b:3.5082288744571777\n",
      "3400 mse is 14.780052222089967, paramters w:1.0289094443219298, b:3.570691475419298\n",
      "3500 mse is 14.706297110888903, paramters w:1.027174467495413, b:3.63139585221924\n",
      "3600 mse is 14.63663574219302, paramters w:1.0254883275429652, b:3.690391496107077\n",
      "3700 mse is 14.570840894764002, paramters w:1.023849649783246, b:3.747726505231884\n",
      "3800 mse is 14.508697959170744, paramters w:1.0222570982300376, b:3.8034476238553494\n",
      "3900 mse is 14.450004237776907, paramters w:1.020709374503036, b:3.8576002804615706\n",
      "4000 mse is 14.394568283582464, paramters w:1.0192052167693053, b:3.910228624794133\n",
      "4100 mse is 14.342209275762384, paramters w:1.0177433987145252, b:3.961375563850649\n",
      "4200 mse is 14.292756429865873, paramters w:1.0163227285431993, b:4.0110827968641045\n",
      "4300 mse is 14.246048440752206, paramters w:1.0149420480070028, b:4.059390849299524\n",
      "4400 mse is 14.201932956446045, paramters w:1.0136002314604833, b:4.106339105893737\n",
      "4500 mse is 14.160266081196253, paramters w:1.0122961849433407, b:4.151965842765031\n",
      "4600 mse is 14.120911906117213, paramters w:1.0110288452885405, b:4.1963082586190605\n",
      "4700 mse is 14.083742065881601, paramters w:1.0097971792555303, b:4.239402505076316\n",
      "4800 mse is 14.048635320018786, paramters w:1.008600182687858, b:4.281283716145919\n",
      "4900 mse is 14.015477157452985, paramters w:1.007436879694499, b:4.3219860368697836\n",
      "5000 mse is 13.984159422991496, paramters w:1.0063063218542294, b:4.361542651160503\n",
      "5100 mse is 13.954579964544278, paramters w:1.0052075874423936, b:4.399985808855613\n",
      "5200 mse is 13.926642299924682, paramters w:1.004139780679438, b:4.437346852010358\n",
      "5300 mse is 13.900255302144126, paramters w:1.0031020310005974, b:4.473656240450337\n",
      "5400 mse is 13.875332902174325, paramters w:1.002093492346138, b:4.50894357660486\n",
      "5500 mse is 13.851793808207697, paramters w:1.00111334247158, b:4.54323762964132\n",
      "5600 mse is 13.829561240499856, paramters w:1.0001607822773337, b:4.57656635892022\n",
      "5700 mse is 13.808562680929795, paramters w:0.9992350351572097, b:4.608956936789957\n",
      "5800 mse is 13.788729636460452, paramters w:0.9983353463652628, b:4.640435770739963\n",
      "5900 mse is 13.769997415728328, paramters w:0.9974609824004617, b:4.671028524930312\n",
      "6000 mse is 13.752304918033412, paramters w:0.9966112304086775, b:4.700760141115253\n",
      "6100 mse is 13.735594434041104, paramters w:0.9957853976015062, b:4.729654858977811\n",
      "6200 mse is 13.719811457546058, paramters w:0.9949828106914497, b:4.757736235891983\n",
      "6300 mse is 13.704904507684086, paramters w:0.9942028153429961, b:4.785027166128666\n",
      "6400 mse is 13.690824961011918, paramters w:0.9934447756391509, b:4.811549899520976\n",
      "6500 mse is 13.677526892907498, paramters w:0.9927080735629846, b:4.837326059604152\n",
      "6600 mse is 13.664966927773158, paramters w:0.9919921084937743, b:4.862376661244864\n",
      "6700 mse is 13.653104097553213, paramters w:0.9912962967173276, b:4.886722127774269\n",
      "6800 mse is 13.641899708104528, paramters w:0.9906200709500901, b:4.9103823076388196\n",
      "6900 mse is 13.631317212984044, paramters w:0.989962879876649, b:4.933376490582359\n",
      "7000 mse is 13.621322094241675, paramters w:0.9893241877002552, b:4.955723423372707\n",
      "7100 mse is 13.611881749829832, paramters w:0.9887034737059963, b:4.977441325085629\n",
      "7200 mse is 13.60296538726214, paramters w:0.988100231836268, b:4.998547901958479\n",
      "7300 mse is 13.594543923174585, paramters w:0.9875139702781927, b:5.019060361825844\n",
      "7400 mse is 13.586589888461463, paramters w:0.9869442110626532, b:5.038995428148766\n",
      "7500 mse is 13.579077338676818, paramters w:0.9863904896746131, b:5.058369353649119\n",
      "7600 mse is 13.571981769408849, paramters w:0.9858523546744045, b:5.077197933560176\n",
      "7700 mse is 13.56528003635151, paramters w:0.9853293673296778, b:5.095496518504174\n",
      "7800 mse is 13.558950279812528, paramters w:0.9848211012577104, b:5.113280027007443\n",
      "7900 mse is 13.55297185341147, paramters w:0.9843271420777837, b:5.130562957663215\n",
      "8000 mse is 13.547325256735489, paramters w:0.9838470870733462, b:5.147359400952075\n",
      "8100 mse is 13.541992071732881, paramters w:0.9833805448636845, b:5.1636830507297145\n",
      "8200 mse is 13.536954902637207, paramters w:0.9829271350848385, b:5.179547215391268\n",
      "8300 mse is 13.532197319225803, paramters w:0.9824864880794966, b:5.194964828721443\n",
      "8400 mse is 13.527703803227702, paramters w:0.9820582445956193, b:5.209948460439218\n",
      "8500 mse is 13.523459697706237, paramters w:0.981642055493549, b:5.224510326445712\n",
      "8600 mse is 13.51945115925107, paramters w:0.9812375814613609, b:5.238662298783598\n",
      "8700 mse is 13.515665112823779, paramters w:0.9808444927382282, b:5.252415915316195\n",
      "8800 mse is 13.512089209109767, paramters w:0.980462468845574, b:5.265782389134077\n",
      "8900 mse is 13.508711784237294, paramters w:0.98009119832579, b:5.27877261769691\n",
      "9000 mse is 13.505521821732275, paramters w:0.9797303784883108, b:5.291397191717996\n",
      "9100 mse is 13.502508916584837, paramters w:0.9793797151628353, b:5.303666403798669\n",
      "9200 mse is 13.499663241310225, paramters w:0.9790389224594944, b:5.315590256819697\n",
      "9300 mse is 13.496975513893553, paramters w:0.9787077225357701, b:5.32717847209646\n",
      "9400 mse is 13.494436967513838, paramters w:0.9783858453699751, b:5.338440497304571\n",
      "9500 mse is 13.492039321948265, paramters w:0.9780730285411086, b:5.349385514182402\n",
      "9600 mse is 13.4897747565639, paramters w:0.9777690170149095, b:5.360022446016802\n",
      "9700 mse is 13.487635884808343, paramters w:0.9774735629359299, b:5.370359964918109\n",
      "9800 mse is 13.485615730116256, paramters w:0.9771864254254647, b:5.38040649889037\n",
      "9900 mse is 13.483707703153323, paramters w:0.9769073703851653, b:5.390170238702542\n",
      "w 0.976638844156133\n",
      "b 5.399565590351456\n",
      "X_test: [33 56]\n",
      "y_pred: [37.628647 60.091341]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "X = np.array([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "y = np.array([5, 8, 16, 19, 30, 35, 30, 43, 41, 44, 58])\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "w, b = fit(X, y, learning_rate=0.001)\n",
    "print(\"w\", w)\n",
    "print(\"b\", b)\n",
    "\n",
    "X_test = np.array([33, 56])\n",
    "y_pred = predict(X_test, w, b)\n",
    "print(\"X_test:\", X_test)\n",
    "print(\"y_pred:\", y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmps460",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
