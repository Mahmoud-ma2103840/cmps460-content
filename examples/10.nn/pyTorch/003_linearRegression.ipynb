{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003_linearRegression.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTUbkrDJw8iR"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maticvl/dataHacker/blob/master/pyTorch/003_linearRegression.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fjCaHeQ5t_K"
      },
      "source": [
        "![datahacker.png](data:image/png;base64,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)\r\n",
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VTd-VSQ8cGP"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcoe9GAFHPx4"
      },
      "source": [
        "x_data = np.array([1, 2, 3, 4, 5])\r\n",
        "y_data = x_data * 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GCIpQ7XHV0L"
      },
      "source": [
        "plt.scatter(x_data, y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S45646t0JZwS"
      },
      "source": [
        "Create a forward propagation function from the following formula $ y = mx + b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzyAlu2cHjcw"
      },
      "source": [
        "def forward(x, w, b=0):\r\n",
        "  y_hat = x * w + b\r\n",
        "  return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42H2Je5EJuML"
      },
      "source": [
        "Create a squared error function for the later calculation of the mean squared error which is calculated as $\\sum_{i=1}^{n}(\\hat{Y}_i - Y_i)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMgoSJkIcLS"
      },
      "source": [
        "def loss(y_hat, y):\r\n",
        "  return (y_hat - y) ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8iOEv5dLOPf"
      },
      "source": [
        "Iterate for `w` that goes from 0 to 4 with a step of 0.1 and calculate the loss depending on the $\\hat{Y} $ that we got by doing the forward propagation. We save all the `losses` and `w` for later plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOhTZA5aKudW"
      },
      "source": [
        "all_w = []\r\n",
        "all_loss = []\r\n",
        "\r\n",
        "for w in np.arange(0, 4, 0.1):\r\n",
        "  l_sum = 0\r\n",
        "\r\n",
        "  for i in range(len(x_data)):\r\n",
        "    y_hat = forward(x_data[i], w)\r\n",
        "    l = loss(y_hat, y_data[i])\r\n",
        "\r\n",
        "    l_sum += l\r\n",
        "  \r\n",
        "  all_w.append(w)\r\n",
        "  all_loss.append(l_sum / len(y_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyEzpR76Y5Gp"
      },
      "source": [
        "plt.stem(all_w, all_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504dWISMLk1k"
      },
      "source": [
        "Creating tensors from the data we created and reshaping it to be `(-1, 1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdpF9r5Nnkif"
      },
      "source": [
        "x_torch = torch.FloatTensor(x_data).reshape(-1, 1)\r\n",
        "y_torch = torch.FloatTensor(y_data).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpyx-1wnzid"
      },
      "source": [
        "x_torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1888hbvOn0c3"
      },
      "source": [
        "y_torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQLxhwBALpoy"
      },
      "source": [
        "Set the weight, `w`, to be 5 and bias, `b`, to be 3 and set the `requires_grad` option to be `True` for the auto gradient calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iIiue1In1mX"
      },
      "source": [
        "w = torch.tensor(5., requires_grad=True)\r\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f892m6crL1YT"
      },
      "source": [
        "Define the learning rate or $ alfa$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRH-KwWWn8M6"
      },
      "source": [
        "lr = 0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dJYvyhbL42s"
      },
      "source": [
        "Iterate 1000 times and do the optimization fo the model parameters `w` and `b`.\r\n",
        "This process consists of 5 steps.\\\r\n",
        "1) Do the forward propagation   `x_torch * w + b`\\\r\n",
        "2) Calculate the MSE\\\r\n",
        "3) Do the backpropagation `.backward()` on the loss that was calculated\\\r\n",
        "4) Update the weight and bias parameter\\\r\n",
        "5) Zero the gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeCWxDkItbQJ"
      },
      "source": [
        "all_w = []\r\n",
        "all_loss = []\r\n",
        "\r\n",
        "for i in range(1000):\r\n",
        "  y_hat = x_torch * w + b\r\n",
        "\r\n",
        "  loss = torch.sum(torch.pow(y_torch - y_hat, 2) / len(y_torch))\r\n",
        "  loss.backward()\r\n",
        "  \r\n",
        "  all_w.append(w.item())\r\n",
        "  all_loss.append(loss.item())\r\n",
        "  with torch.no_grad():\r\n",
        "    w -= lr * w.grad\r\n",
        "    b -= lr * b.grad\r\n",
        "\r\n",
        "    w.grad.zero_()\r\n",
        "    b.grad.zero_()\r\n",
        "\r\n",
        "    all_w.append(w)\r\n",
        "    all_loss.append(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHM12u1yMYOt"
      },
      "source": [
        "Do some predictions on the `x_torch` using `w` and `b`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf37fFAxwWlr"
      },
      "source": [
        "y_pred = x_torch * w + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bPuQiQ-Md--"
      },
      "source": [
        "We can see that the prediction is correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2-ejk8ow6zR"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVnb4gotp364"
      },
      "source": [
        "y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqy8f5OpMhSq"
      },
      "source": [
        "Plot the original values as green dots and the prediction with a blue line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKoWFkw3w9Fu"
      },
      "source": [
        "plt.plot(x_torch, y_torch, 'go')\r\n",
        "plt.plot(x_torch, y_pred.detach().numpy(), '--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0eYz07RMmFi"
      },
      "source": [
        "We can also see that the weight and bias are correctly calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0KmLiLPEMGn"
      },
      "source": [
        "w, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHPZJnQQMqRL"
      },
      "source": [
        "Test it on the number `3.5`, we should get `7`. `x * 2 + 0`, where `2` represents the `w` or weight and `0` represents the bias or `b`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQRca1FdEcwG"
      },
      "source": [
        "x_test = torch.Tensor([3.5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpIW8ZTeEhQB"
      },
      "source": [
        "x_test * w + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-3StFn2NfvF"
      },
      "source": [
        "## Full PyTorch implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohcS57yTM7BY"
      },
      "source": [
        "Create a random set of numbers, 50 randomly generated x values in the interval from `[0, 10]`. Set `Y` to be `x * 3 - 4`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xniBA4JuzMyU"
      },
      "source": [
        "x = np.random.rand(50)\r\n",
        "x = x * 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-8muio-zRmo"
      },
      "source": [
        "y = x * 3 - 4\r\n",
        "y += np.random.randn(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElE5IopLNDs1"
      },
      "source": [
        "Generate the Linear Model class using `torch.nn.Module`. In this class we create a initialization where we create one linear layer that we later use in the function `forward`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIrkn1VEje7"
      },
      "source": [
        "class LinearModel(torch.nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(LinearModel, self).__init__()\r\n",
        "    self.linear = torch.nn.Linear(1, 1)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx8K16yJNPm4"
      },
      "source": [
        "Transform the `x` and `y` to be tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--KKjEPhzXVL"
      },
      "source": [
        "x_torch = torch.FloatTensor(x).reshape(-1, 1)\r\n",
        "y_torch = torch.FloatTensor(y).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y3_2Z_gNVf-"
      },
      "source": [
        "Call the `LinearModel` class that we created and create a loss function and also a optimizer that will be used for optimizing or updating the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyFZv9bWmv2i"
      },
      "source": [
        "model = LinearModel()\r\n",
        "criterion = torch.nn.MSELoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Q4eTdINmI7"
      },
      "source": [
        "Train the model for 1000 epochs.\\\r\n",
        "1) Do the forward propagation.\\\r\n",
        "2) Calculate loss\\\r\n",
        "3) Backpropagation\\\r\n",
        "4) Update the parameters by using `optimizer.step()`\\\r\n",
        "5) Zero the gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6YJpfmC4L0v"
      },
      "source": [
        "all_loss = []\r\n",
        "\r\n",
        "for epoch in range(1000):\r\n",
        "  y_hat = model(x_torch)\r\n",
        "\r\n",
        "  loss = criterion(y_hat, y_torch)\r\n",
        "  loss.backward()\r\n",
        "  all_loss.append(loss.item())\r\n",
        "\r\n",
        "  optimizer.step()\r\n",
        "  optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4vxNGE2OC2L"
      },
      "source": [
        "Do some predictions on `x_torch`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kctc-Vbi7IVt"
      },
      "source": [
        "y_pred = model.forward(x_torch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pikJiC67aNy"
      },
      "source": [
        "plt.plot(x_torch, y_torch, 'go')\r\n",
        "plt.plot(x_torch, y_pred.detach().numpy(), '--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fm5Wtk5OGhz"
      },
      "source": [
        "Print out the paramters `w` and `b` that are stored in `model.named_parameters()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96v2zeho7c44"
      },
      "source": [
        "for name, param in model.named_parameters():\r\n",
        "  print(name, param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGILJg7pOM_d"
      },
      "source": [
        "Plot the loss that we saved in the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT91knQR_Giz"
      },
      "source": [
        "plt.plot(np.arange(0, 200, 1), all_loss[:200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XHSgknj_ZZ9"
      },
      "source": [
        "all_loss[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj1Xgr2o_cs5"
      },
      "source": [
        "all_loss[-1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}